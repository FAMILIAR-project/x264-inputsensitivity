{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.stats as sc\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from learner.mlearner import learn_with_interactions, learn_without_interactions, mean_absolute_percentage_error, sample_random\n",
    "from learner.model import genModelTermsfromString, Model, genModelfromCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 videos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_cabac</th>\n",
       "      <th>no_fast_pskip</th>\n",
       "      <th>no_mbtree</th>\n",
       "      <th>rc_lookahead</th>\n",
       "      <th>ref</th>\n",
       "      <th>elapsedtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>5.074625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>5.902625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.908125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>5.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>4.329125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>4.710125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3.624125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3.680875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3.512125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>6.309250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_cabac  no_fast_pskip  no_mbtree  rc_lookahead  ref  elapsedtime\n",
       "0     False           True      False            20    9     5.074625\n",
       "1      True           True      False            40    9     5.902625\n",
       "2     False          False       True            40    1     2.908125\n",
       "3      True           True       True            40    9     5.027500\n",
       "4     False          False      False            60    5     4.329125\n",
       "5      True           True      False            60    5     4.710125\n",
       "6     False          False      False            60    1     3.624125\n",
       "7      True           True      False            60    1     3.680875\n",
       "8     False           True      False            60    1     3.512125\n",
       "9     False           True      False            60    9     6.309250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFolderName = '../data_luc/video/'\n",
    "\n",
    "listVideoName =   ['x264-1908-bridgefar-wasm/x264-results1.csv', \n",
    "                   'x264-1908-ice-wasm/x264-results1.csv',\n",
    "                   'x264-1908-flower-wasm/x264-results1.csv', \n",
    "                   'x264-1908-caire-wasm/x264-results1.csv',\n",
    "                   'x264-0208-sintel-calda-wasm/x264-results1.csv', \n",
    "                   'x264-1908-footballcif-wasm/x264-results1.csv',\n",
    "                   'x264-0308-crowd_run-wasm/x264-results1.csv', \n",
    "                   'x264-0608-blue-wasm/x264-results1.csv',\n",
    "                   'x264-0608-people-wasm/x264-results1.csv', \n",
    "                   'x264-1908-sunflowers-wasm/x264-results1.csv',\n",
    "                   'x264-0408-deadline-wasm/x264-results1.csv', \n",
    "                   'x264-2108-bridgeclose-wasm/x264-results1.csv',\n",
    "                   'x264-1908-husky-wasm/x264-results1.csv', \n",
    "                   'x264-1908-tennis-wasm/x264-results1.csv',\n",
    "                   'x264-1908-riverbed-wasm/x264-results1.csv', \n",
    "                   'x264-0608-park-wasm/x264-results1.csv',\n",
    "                   'x264-0508-soccer-wasm/x264-results1.csv']\n",
    "\n",
    "# creation of the list of videos (for each video: x264 configurations + measurements)\n",
    "listVideo = []\n",
    "\n",
    "for vn in listVideoName:\n",
    "    listVideo.append(pd.read_csv(open(dataFolderName+vn,\"r\")))\n",
    "    \n",
    "nbVideos = len(listVideo)\n",
    "\n",
    "# test\n",
    "print(\"There are \" + str(len(listVideo)) + \" videos\")\n",
    "assert (len(listVideoName) == len(listVideo))\n",
    "\n",
    "\n",
    "#print a csv\n",
    "listVideo[7].drop(['no_8x8dct', 'no_deblock', 'no_mixed_refs', 'no_weightb', 'size', 'usertime', 'systemtime', 'H264', 'no_asm', 'configurationID'], axis=1)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2s implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModel(model, config):\n",
    "    return float(model.evaluateModelFast(np.matrix(config))[0])\n",
    "def learnModel(X, y, withInteractions):\n",
    "    if (withInteractions):\n",
    "        m = learn_with_interactions(X, y)\n",
    "    else:\n",
    "        m = learn_without_interactions(np.asarray(X), np.asarray(y))\n",
    "    learned_model_terms = genModelfromCoeff(m.named_steps['linear'].coef_, ndim)\n",
    "    return Model(learned_model_terms, ndim)\n",
    "\n",
    "# for this tutorial we assume 20 options:\n",
    "ndim = 20 \n",
    "# defines the dimension of the model, i.e., the number of variables in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see how we evaluate the model with specific input\n",
    "c0 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "c1 = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "c2 = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "c3 = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "c23 = [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " [10, 12, 15, 13, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's define a list of configurations and a corresponding list of measurement results\n",
    "X = [c0, c1, c2, c3, c23]\n",
    "y = [10, 12, 15, 13, 10]\n",
    "\n",
    "X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.00 * o0 + 1.00 * o1 + -1.00 * o2 + -3.3306690738754696e-16'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_model = learnModel(X, y, 0)\n",
    "learned_model.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.00 * o0 + 5.00 * o1 + 3.00 * o2 + -8.00 * o0 * o19 + -8.00 * o1 * o18 + -8.00 * o2 * o17 + -8.00 * o3 * o16 + -8.00 * o4 * o15 + -8.00 * o5 * o14 + -8.00 * o6 * o13 + -8.00 * o7 * o12 + -8.00 * o8 * o11 + -8.00 * o9 * o10 + -8.881784197001252e-16'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_model = learnModel(X, y, 1)\n",
    "learned_model.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a model, in this case a polynomial model\n",
    "# Polynomial models are a great tool for determining which input factors drive responses and in what direction.\n",
    "# Here we define a model with 20 dimensions, each variable represents a dimension and influence of each variable\n",
    "# is different, e.g., o0 has the coefficient of 1, while o1 has the coefficient of 2 so its effect is twice comparing\n",
    "# with o0. Also, we have two terms that represents the interactions of variables, e.g., 3 * o3 * o6.\n",
    "\n",
    "true_model = \"\"\"10 + 1.00 * o0 + 2.00 * o1 + 3.00 * o2 +\n",
    "4.00 * o3 + 5.00 * o4 + 6.00 * o5 + 7.00 * o6 + 8.00 * o7 + \n",
    "1.00 * o8 + 2.00 * o9 + 3.00 * o10 + 4.00 * o11 + 5.00 * o12 + \n",
    "6.00 * o13 + 7.00 * o14 + 8.00 * o15 + 1.00 * o16 + 2.00 * o17 + \n",
    "3.00 * o18 + 4.00 * o19 + 1 * o0 * o1 + 3 * o3 * o6\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.00 * o0 + 2.00 * o1 + 3.00 * o2 + 4.00 * o3 + 5.00 * o4 + 6.00 * o5 + 7.00 * o6 + 8.00 * o7 + 1.00 * o8 + 2.00 * o9 + 3.00 * o10 + 4.00 * o11 + 5.00 * o12 + 6.00 * o13 + 7.00 * o14 + 8.00 * o15 + 1.00 * o16 + 2.00 * o17 + 3.00 * o18 + 4.00 * o19 + 1.00 * o0 * o1 + 3.00 * o3 * o6 + 10.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model above is just a representation in string, \n",
    "# so we need to build a model that we can evaluate given an input\n",
    "model_terms = genModelTermsfromString(true_model)\n",
    "true_model = Model(model_terms, ndim)\n",
    "true_model.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " array([10., 11., 12., 13., 15.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could also look up specific measurement results in a secret model\n",
    "# that we use as ground truth:\n",
    "# sample_random(ndim=ndim, budget=1000)\n",
    "\n",
    "y = true_model.evaluateModelFast(np.asarray(X))\n",
    "\n",
    "X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.00 * o0 + 2.00 * o1 + 3.00 * o2 + 0.00 * o0 * o19 + 0.00 * o1 * o18 + 0.00 * o2 * o17 + 0.00 * o3 * o16 + 0.00 * o4 * o15 + 0.00 * o5 * o14 + 0.00 * o6 * o13 + 0.00 * o7 * o12 + 0.00 * o8 * o11 + 0.00 * o9 * o10'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned_model = learnModel(X, y, 1)\n",
    "learned_model.toString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.05755356456655"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we first consider sampling some ground truth data, note that we sample again \n",
    "# in order to test on data that was not necessarily used for learning the model\n",
    "X = sample_random(ndim=ndim, budget=10000)\n",
    "y_true = true_model.evaluateModelFast(X)\n",
    "y_pred = learned_model.evaluateModelFast(X)\n",
    "err = mean_absolute_percentage_error(y_true=y_true, y_pred=y_pred)\n",
    "err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbVideos = len(listVideo)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))\n",
    "\n",
    "pct_test = 0.3\n",
    "\n",
    "mat_mape_l2s = np.ones(nbVideos*nbVideos).reshape(nbVideos, nbVideos)\n",
    "\n",
    "random_state = np.random.randint(0,1000)\n",
    "\n",
    "for i in range(nbVideos):\n",
    "    for j in range(nbVideos):\n",
    "\n",
    "        source = listVideo[i] #i\n",
    "        X_src = source[['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip',\n",
    "            'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']] \n",
    "        y_src = np.array(source['elapsedtime'], \n",
    "                         dtype=float)\n",
    "\n",
    "        X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_src, \n",
    "                                                                            y_src, \n",
    "                                                                            test_size=pct_test, \n",
    "                                                                            random_state=random_state)\n",
    "\n",
    "        target = listVideo[j] #j\n",
    "        X_tgt = target[['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip',\n",
    "            'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']] \n",
    "        y_tgt = np.array(target['elapsedtime'], \n",
    "                         dtype=float)\n",
    "\n",
    "        X_tgt_train, X_tgt_test, y_tgt_train, y_tgt_test = train_test_split(X_tgt, \n",
    "                                                                            y_tgt, \n",
    "                                                                            test_size=pct_test, \n",
    "                                                                            random_state=random_state)\n",
    "\n",
    "        coef, intercept, r_value, _ , std_err = stats.linregress(y_src_train, y_tgt_train)\n",
    "\n",
    "        clf = RandomForestRegressor()\n",
    "        clf.fit(X_src_train, y_src_train)\n",
    "        \n",
    "        y_src_pred_test = clf.predict(X_src_test)\n",
    "        \n",
    "        y_tgt_pred_test = intercept + coef*y_src_pred_test\n",
    "\n",
    "        mat_mape_l2s[i][j] = min(mape(y_tgt_test, y_tgt_pred_test),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.05, \n",
    "                       threshold_out = 0.06, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, pd.DataFrame(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = np.argmin(new_pval)\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.5}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, pd.DataFrame(X[included])).fit()\n",
    "        pvalues = model.pvalues\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = np.argmax(pvalues)\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.5}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "\n",
    "pct_test = 0.3\n",
    "\n",
    "random_state = np.random.randint(0,1000)\n",
    "\n",
    "keep_features = ['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip', \n",
    "                 'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']\n",
    "\n",
    "\n",
    "for i in range(len(listVideo)):\n",
    "        \n",
    "    source = listVideo[i] #i\n",
    "\n",
    "    X_src = pd.get_dummies(pd.DataFrame(np.array(source[keep_features], dtype =int)))\n",
    "    \n",
    "    y_src = np.array(source['elapsedtime'], dtype=float)\n",
    "    X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_src, \n",
    "                                                                        y_src, \n",
    "                                                                        test_size=pct_test, \n",
    "                                                                        random_state=random_state)\n",
    "    \n",
    "    \"\"\"target = listVideo[j] #j\n",
    "\n",
    "    X_tgt = target[['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip',\n",
    "        'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']] \n",
    "    y_tgt = np.array(target['elapsedtime'], \n",
    "                     dtype=float)\n",
    "    X_tgt_train, X_tgt_test, y_tgt_train, y_tgt_test = train_test_split(X_tgt, \n",
    "                                                                        y_tgt, \n",
    "                                                                        test_size=pct_test, \n",
    "                                                                        random_state=random_state)\n",
    "    \"\"\"\n",
    "    \n",
    "    result = stepwise_selection(X_src, y_src, verbose = False)\n",
    "\n",
    "    #print('resulting features:')\n",
    "    #print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = pd.DataFrame(np.array(source[['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip',\n",
    "    'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']], dtype =int), columns=name)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name = ['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip',\n",
    "    'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']\n",
    "\n",
    "\n",
    "for i in range(len(name)):\n",
    "    feature = a[name[i]]\n",
    "    f_dummy = pd.get_dummies(feature, prefix = name[i], drop_first = True)\n",
    "    col = f_dummy.columns\n",
    "    for j in range(len(col)):\n",
    "        print(f_dummy[col[j]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.get_dummies(source[['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip',\n",
    "    'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
