{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.stats as sc\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from learner.mlearner import learn_with_interactions, learn_without_interactions, sample_random, stepwise_feature_selection\n",
    "from learner.model import genModelTermsfromString, Model, genModelfromCoeff\n",
    "\n",
    "\n",
    "from import_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/llesoil/anaconda3/envs/x264:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "_tflow_select             2.3.0                       mkl  \r\n",
      "absl-py                   0.9.0                    py37_0  \r\n",
      "asn1crypto                1.3.0                    py37_0  \r\n",
      "astor                     0.8.0                    py37_0  \r\n",
      "attrs                     19.3.0                     py_0  \r\n",
      "backcall                  0.1.0                    py37_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    3.1.4                      py_0  \r\n",
      "blinker                   1.4                      py37_0  \r\n",
      "c-ares                    1.15.0            h7b6447c_1001  \r\n",
      "ca-certificates           2020.6.20            hecda079_0    conda-forge\r\n",
      "cachetools                3.1.1                      py_0  \r\n",
      "certifi                   2020.6.20        py37hc8dfbb8_0    conda-forge\r\n",
      "cffi                      1.14.0           py37h2e261b9_0  \r\n",
      "chardet                   3.0.4                 py37_1003  \r\n",
      "click                     7.1.1                      py_0  \r\n",
      "cryptography              2.8              py37h1ba5d50_0  \r\n",
      "cycler                    0.10.0                   py37_0  \r\n",
      "dbus                      1.13.12              h746ee38_0  \r\n",
      "decorator                 4.4.2                      py_0  \r\n",
      "defusedxml                0.6.0                      py_0  \r\n",
      "entrypoints               0.3                      py37_0  \r\n",
      "expat                     2.2.6                he6710b0_0  \r\n",
      "factor_analyzer           0.3.2              pyh39e3cac_0    desilinguist\r\n",
      "fastcache                 1.1.0            py37h7b6447c_0  \r\n",
      "fastcluster               1.1.26                   pypi_0    pypi\r\n",
      "fontconfig                2.13.0               h9420a91_0  \r\n",
      "freetype                  2.9.1                h8a8886c_1  \r\n",
      "gast                      0.2.2                    py37_0  \r\n",
      "glib                      2.63.1               h5a9c865_0  \r\n",
      "gmp                       6.1.2                h6c8ec71_1  \r\n",
      "gmpy2                     2.0.8            py37h10f8cd9_2  \r\n",
      "google-auth               1.13.1                     py_0  \r\n",
      "google-auth-oauthlib      0.4.1                      py_2  \r\n",
      "google-pasta              0.2.0                      py_0  \r\n",
      "grpcio                    1.27.2           py37hf8bcb03_0  \r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb453b48_1  \r\n",
      "h5py                      2.10.0           py37h7918eee_0  \r\n",
      "hdf5                      1.10.4               hb1b8bf9_0  \r\n",
      "icu                       58.2                 he6710b0_3  \r\n",
      "idna                      2.9                        py_1  \r\n",
      "importlib_metadata        1.5.0                    py37_0  \r\n",
      "intel-openmp              2020.0                      166  \r\n",
      "ipykernel                 5.1.4            py37h39e3cac_0  \r\n",
      "ipython                   7.13.0           py37h5ca1d4c_0  \r\n",
      "ipython_genutils          0.2.0                    py37_0  \r\n",
      "jedi                      0.17.0                   py37_0  \r\n",
      "jinja2                    2.11.2                     py_0  \r\n",
      "joblib                    0.14.1                     py_0  \r\n",
      "jpeg                      9b                   h024ee3a_2  \r\n",
      "jsonschema                3.2.0                    py37_0  \r\n",
      "jupyter_client            6.1.2                      py_0  \r\n",
      "jupyter_core              4.6.3                    py37_0  \r\n",
      "keras                     2.3.1                         0  \r\n",
      "keras-applications        1.0.8                      py_0  \r\n",
      "keras-base                2.3.1                    py37_0  \r\n",
      "keras-preprocessing       1.1.0                      py_1  \r\n",
      "kiwisolver                1.1.0            py37he6710b0_0  \r\n",
      "ld_impl_linux-64          2.33.1               h53a641e_7  \r\n",
      "learner                   0.1.0                    pypi_0    pypi\r\n",
      "libedit                   3.1.20181209         hc058e9b_0  \r\n",
      "libffi                    3.2.1                hd88cf55_4  \r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0  \r\n",
      "libgfortran-ng            7.3.0                hdf63c60_0  \r\n",
      "libpng                    1.6.37               hbc83047_0  \r\n",
      "libprotobuf               3.11.4               hd408876_0  \r\n",
      "libsodium                 1.0.16               h1bed415_0  \r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0  \r\n",
      "libuuid                   1.0.3                h1bed415_2  \r\n",
      "libxcb                    1.13                 h1bed415_1  \r\n",
      "libxml2                   2.9.9                hea5a465_1  \r\n",
      "markdown                  3.1.1                    py37_0  \r\n",
      "markupsafe                1.1.1            py37h7b6447c_0  \r\n",
      "matplotlib                3.1.3                    py37_0  \r\n",
      "matplotlib-base           3.1.3            py37hef1b27d_0  \r\n",
      "mistune                   0.8.4            py37h7b6447c_0  \r\n",
      "mkl                       2020.0                      166  \r\n",
      "mkl-service               2.3.0            py37he904b0f_0  \r\n",
      "mkl_fft                   1.0.15           py37ha843d7b_0  \r\n",
      "mkl_random                1.1.0            py37hd6b4f25_0  \r\n",
      "more-itertools            8.2.0                      py_0  \r\n",
      "mpc                       1.1.0                h10f8cd9_1  \r\n",
      "mpfr                      4.0.1                hdf1c602_3  \r\n",
      "mpmath                    1.1.0                    py37_0  \r\n",
      "nbconvert                 5.6.1                    py37_0  \r\n",
      "nbformat                  5.0.4                      py_0  \r\n",
      "ncurses                   6.2                  he6710b0_1  \r\n",
      "nltk                      3.5                        py_0    anaconda\r\n",
      "notebook                  6.0.1                    py37_0  \r\n",
      "numpy                     1.18.1                   pypi_0    pypi\r\n",
      "numpy-base                1.18.1           py37hde5b4d6_1  \r\n",
      "oauthlib                  3.1.0                      py_0  \r\n",
      "opencv-contrib-python     4.2.0.32                 pypi_0    pypi\r\n",
      "openssl                   1.1.1g               h516909a_0    conda-forge\r\n",
      "opt_einsum                3.1.0                      py_0  \r\n",
      "packaging                 20.3                       py_0  \r\n",
      "pandas                    1.0.3            py37h0573a6f_0  \r\n",
      "pandoc                    2.2.3.2                       0  \r\n",
      "pandocfilters             1.4.2                    py37_1  \r\n",
      "parso                     0.7.0                      py_0  \r\n",
      "patsy                     0.5.1                    py37_0  \r\n",
      "pcre                      8.43                 he6710b0_0  \r\n",
      "pexpect                   4.8.0                    py37_0  \r\n",
      "pickleshare               0.7.5                    py37_0  \r\n",
      "pip                       20.0.2                   py37_1  \r\n",
      "pluggy                    0.13.1                   py37_0  \r\n",
      "prometheus_client         0.7.1                      py_0  \r\n",
      "prompt-toolkit            3.0.4                      py_0  \r\n",
      "prompt_toolkit            3.0.4                         0  \r\n",
      "protobuf                  3.11.4           py37he6710b0_0  \r\n",
      "ptyprocess                0.6.0                    py37_0  \r\n",
      "py                        1.8.1                      py_0  \r\n",
      "pyasn1                    0.4.8                      py_0  \r\n",
      "pyasn1-modules            0.2.7                      py_0  \r\n",
      "pycparser                 2.20                       py_0  \r\n",
      "pygments                  2.6.1                      py_0  \r\n",
      "pyjwt                     1.7.1                    py37_0  \r\n",
      "pyopenssl                 19.1.0                   py37_0  \r\n",
      "pyparsing                 2.4.6                      py_0  \r\n",
      "pyqt                      5.9.2            py37h05f1152_2  \r\n",
      "pyrsistent                0.16.0           py37h7b6447c_0  \r\n",
      "pysocks                   1.7.1                    py37_0  \r\n",
      "pytest                    5.4.1                    py37_0  \r\n",
      "python                    3.7.6                h0371630_2  \r\n",
      "python-dateutil           2.8.1                      py_0  \r\n",
      "python_abi                3.7                     1_cp37m    conda-forge\r\n",
      "pytz                      2019.3                     py_0  \r\n",
      "pyyaml                    5.3.1            py37h7b6447c_0  \r\n",
      "pyzmq                     18.1.1           py37he6710b0_0  \r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "readline                  7.0                  h7b6447c_5  \r\n",
      "regex                     2020.6.8         py37h7b6447c_0    anaconda\r\n",
      "requests                  2.23.0                   py37_0  \r\n",
      "requests-oauthlib         1.3.0                      py_0  \r\n",
      "rsa                       4.0                        py_0  \r\n",
      "salib                     1.1.2                      py_0    conda-forge\r\n",
      "scikit-learn              0.22.1           py37hd81dba3_0  \r\n",
      "scipy                     1.4.1            py37h0b6359f_0  \r\n",
      "seaborn                   0.10.0                     py_0  \r\n",
      "send2trash                1.5.0                    py37_0  \r\n",
      "setuptools                46.1.3                   py37_0  \r\n",
      "sip                       4.19.8           py37hf484d3e_0  \r\n",
      "six                       1.14.0                   py37_0  \r\n",
      "sqlite                    3.31.1               h62c20be_1  \r\n",
      "statsmodels               0.11.1           py37h8f50634_1    conda-forge\r\n",
      "sympy                     1.5.1                    py37_0  \r\n",
      "tensorboard               2.1.0                     py3_0  \r\n",
      "tensorflow                2.1.0           mkl_py37h80a91df_0  \r\n",
      "tensorflow-base           2.1.0           mkl_py37h6d63fb7_0  \r\n",
      "tensorflow-estimator      2.1.0              pyhd54b08b_0  \r\n",
      "termcolor                 1.1.0                    py37_1  \r\n",
      "terminado                 0.8.3                    py37_0  \r\n",
      "testpath                  0.4.4                      py_0  \r\n",
      "tk                        8.6.8                hbc83047_0  \r\n",
      "tornado                   6.0.4            py37h7b6447c_1  \r\n",
      "tqdm                      4.47.0                     py_0    anaconda\r\n",
      "traitlets                 4.3.3                    py37_0  \r\n",
      "urllib3                   1.25.8                   py37_0  \r\n",
      "wcwidth                   0.1.9                      py_0  \r\n",
      "webencodings              0.5.1                    py37_1  \r\n",
      "werkzeug                  1.0.1                      py_0  \r\n",
      "wheel                     0.34.2                   py37_0  \r\n",
      "wrapt                     1.12.1           py37h7b6447c_1  \r\n",
      "xz                        5.2.5                h7b6447c_0  \r\n",
      "yaml                      0.1.7                had09818_2  \r\n",
      "zeromq                    4.3.1                he6710b0_3  \r\n",
      "zipp                      3.1.0                      py_0  \r\n",
      "zlib                      1.2.11               h7b6447c_3  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  configurationID no_8x8dct no_asm no_cabac no_deblock  \\\n",
      "0           0                1      True  False    False       True   \n",
      "1           1             1001     False  False     True       True   \n",
      "2           2             1002      True  False    False      False   \n",
      "3           3             1003     False  False    False       True   \n",
      "4           4             1004     False  False     True      False   \n",
      "\n",
      "  no_fast_pskip no_mbtree no_mixed_refs no_weightb  rc_lookahead  ref  frames  \\\n",
      "0          True     False          True       True          20.0  9.0    1374   \n",
      "1          True      True          True       True          20.0  1.0    1374   \n",
      "2          True     False          True       True          60.0  5.0    1374   \n",
      "3          True      True         False      False          20.0  9.0    1374   \n",
      "4         False      True          True      False          20.0  9.0    1374   \n",
      "\n",
      "     cpu       fps     kbs  etime       size  \n",
      "0  703.2  1315.615  225.03  1.052  1289567.0  \n",
      "1  726.8  1832.999  281.44  0.759  1612870.0  \n",
      "2  614.3  1319.635  239.30  1.049  1371341.0  \n",
      "3  631.4   935.269  249.34  1.474  1428898.0  \n",
      "4  728.1  1315.951  270.22  1.055  1548544.0  \n",
      "There are 25 videos\n"
     ]
    }
   ],
   "source": [
    "listVideo = load_data(drop_default=True)\n",
    "\n",
    "nbVideos = len(listVideo)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))\n",
    "\n",
    "predDimension=\"etime\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2s implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extraction Process of Performance Models\n",
    "\n",
    "Select a good model for predicting the performance of the source video\n",
    "\n",
    "Original files:\n",
    "- https://github.com/cmu-mars/model-learner/blob/tutorial/learner/mlearner.py for the stepwise selection\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html for the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @PooyanJamshidi:\n",
    "# We just change slightly some functions from the original repository,\n",
    "# mainly because we don't want to add a constant in the model\n",
    "# + steps 2 and 3 were implemented in matlab but we did not find them in python\n",
    "\n",
    "def stepwise_selection(X, y,\n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \n",
    "    ndim = X.shape[1]\n",
    "    features = [i for i in range(ndim)]\n",
    "    included = list(initial_list)\n",
    "    \n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        # forward step (removed a constant)\n",
    "        excluded = list(set(features)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, pd.DataFrame(X[included+[new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add {:30} with p-value {:.5}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, pd.DataFrame(X[included])).fit()\n",
    "        pvalues = model.pvalues\n",
    "        worst_pval = pvalues.max()\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.5}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            if verbose:\n",
    "                print(\"Construction of the model completed!\")\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                              0 with p-value 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                             12 with p-value 3.6016e-115\n",
      "Add                              7 with p-value 2.6613e-135\n",
      "Add                             82 with p-value 6.4634e-110\n",
      "Add                              6 with p-value 2.4987e-76\n",
      "Add                             13 with p-value 2.8128e-87\n",
      "Add                             14 with p-value 0.0\n",
      "Add                              3 with p-value 8.6971e-72\n",
      "Add                             84 with p-value 1.7216e-79\n",
      "Add                              1 with p-value 3.3535e-85\n",
      "Add                             83 with p-value 3.7657e-74\n",
      "Add                             75 with p-value 7.1947e-58\n",
      "Add                             70 with p-value 6.7114e-69\n",
      "Add                              9 with p-value 1.3804e-79\n",
      "Add                             72 with p-value 3.0565e-115\n",
      "Add                             42 with p-value 3.7652e-66\n",
      "Add                             10 with p-value 6.438e-24\n",
      "Add                             11 with p-value 0.0\n",
      "Add                             73 with p-value 2.424e-26\n",
      "Add                             74 with p-value 1.0966e-198\n",
      "Add                             50 with p-value 1.701e-12\n",
      "Add                             16 with p-value 5.4314e-08\n",
      "Add                             93 with p-value 4.2759e-07\n",
      "Add                             27 with p-value 4.0302e-07\n",
      "Add                             19 with p-value 1.5586e-06\n",
      "Add                             77 with p-value 4.8452e-06\n",
      "Add                             43 with p-value 0.00023504\n",
      "Add                              4 with p-value 0.0015007\n",
      "Add                             45 with p-value 0.0017828\n",
      "Add                             79 with p-value 0.0026613\n",
      "Construction of the model completed!\n"
     ]
    }
   ],
   "source": [
    "# to sample the source and the target using the same seed\n",
    "random_state = np.random.randint(0,1000)\n",
    "\n",
    "# a list of features to keep as explicative variables\n",
    "keep_features = ['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip', \n",
    "                 'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']\n",
    "\n",
    "# ordinal data to convert into dummies\n",
    "to_dummy_features = ['rc_lookahead','ref']\n",
    "\n",
    "\n",
    "# percentage of configuration used for test\n",
    "pct_test = 0.7\n",
    "\n",
    "# the source video\n",
    "source = listVideo[1]\n",
    "\n",
    "\n",
    "# transform some variables into dummies, to fit the orginal paper\n",
    "# since we don't want to introduce a meaningless constant in the model, \n",
    "# we have to keep all columns\n",
    "\n",
    "dummies = pd.get_dummies(source[keep_features], \n",
    "                   drop_first = False,\n",
    "                   columns=to_dummy_features)\n",
    "\n",
    "X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "# add interactions\n",
    "poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "# performance variable, to predict\n",
    "y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "# split train test\n",
    "X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "                                                                    y_src, \n",
    "                                                                    test_size=pct_test, \n",
    "                                                                    random_state=random_state)\n",
    "\n",
    "# the index of the selected features\n",
    "selected_features = stepwise_selection(X_interact, y_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Active Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A - ] Exploitation : use the source's prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (i) Sort the coefficients of the previous constructed model\n",
    "\n",
    "##### (ii) Choose the coefficient with the highest value\n",
    "\n",
    "##### (iii) Select the configurations with this feature activated\n",
    "\n",
    "\n",
    "\n",
    "I assumed it was recursive, with a decreasing influence in the selection for a decreasing importance in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature : 6\n",
      "Feature : 72\n",
      "Feature : 73\n",
      "Feature : 74\n",
      "Feature : 12\n",
      "Feature : 13\n",
      "Feature : 14\n",
      "Feature : 11\n",
      "Feature : 10\n",
      "Feature : 9\n",
      "Feature : 7\n",
      "Added 32 values, 28 left to choose \n",
      "\n",
      "Feature : 82\n",
      "Feature : 83\n",
      "Feature : 84\n",
      "Feature : 0\n",
      "Feature : 3\n",
      "Added 16 values, 12 left to choose \n",
      "\n",
      "Feature : 75\n",
      "Feature : 70\n",
      "Feature : 1\n",
      "Added 8 values, 4 left to choose \n",
      "\n",
      "Feature : 42\n",
      "Feature : 50\n",
      "Feature : 16\n",
      "Feature : 93\n",
      "Feature : 77\n",
      "Feature : 27\n",
      "Feature : 19\n",
      "Feature : 43\n",
      "Feature : 45\n",
      "Feature : 79\n",
      "Feature : 4\n",
      "Added 4 values, 0 left to choose \n",
      "\n",
      "Done!\n",
      "\n",
      "Selected : [1, 13, 76, 116, 125, 128, 163, 205, 241, 280, 367, 378, 412, 431, 455, 466, 519, 577, 618, 682, 750, 765, 790, 804, 817, 835, 875, 900, 942, 1005, 1009, 1100, 21, 137, 195, 287, 405, 407, 514, 616, 641, 778, 832, 848, 874, 897, 973, 1110, 5, 620, 633, 949, 1018, 1075, 1098, 1150, 12, 625, 747, 1030]\n"
     ]
    }
   ],
   "source": [
    "ratio_exploitation = 0.3\n",
    "config_tot = 200\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(X_interact[selected_features], y_src)\n",
    "\n",
    "sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "\n",
    "nb_config_selected = 0\n",
    "\n",
    "assert X_interact.shape[0] >= nb_config_exploitation ; \" Too many configurations to select ! \"\n",
    "\n",
    "def select_exploitation(df, sc, config_selected):\n",
    "    \n",
    "    #number of config left to choose\n",
    "    nb_config = int(nb_config_exploitation - len(config_selected))\n",
    "    \n",
    "    if nb_config == 0:\n",
    "        print(\"Done!\\n\")\n",
    "        return config_selected\n",
    "    \n",
    "    # if we don't have any important coefficient left to help us choose configs\n",
    "    # we take the nb_config first configurations\n",
    "    if len(sc) == 0:\n",
    "        print(\"Selecting \" + str(nb_config) + \" configurations from the rest of the dataset!\")\n",
    "        for conf in df.index[0:nb_config]:\n",
    "            config_selected.append(conf)\n",
    "        return config_selected\n",
    "    \n",
    "    # otherwise we just use the best coef to choose configs\n",
    "    else:\n",
    "        \n",
    "        # we choose the best features coef (biggest absolute value)\n",
    "        most_important_coef = sc[0]\n",
    "        \n",
    "        print(\"Feature : \" + str(most_important_coef))\n",
    "        \n",
    "        # configs with this feature activated\n",
    "        imp_index = np.where(df[most_important_coef]==1)[0]\n",
    "\n",
    "        # number of configs with this feature activated\n",
    "        nb_imp_index = len(imp_index)\n",
    "\n",
    "        # if we have more values to choose \n",
    "        # than the number of configurations with the best feature activated\n",
    "        # we add all the configuration to the selected set\n",
    "        # and we select the rest of the configuration based on other coefficients\n",
    "        if nb_imp_index <= nb_config:\n",
    "            for conf in df.iloc[imp_index].index:\n",
    "                config_selected.append(conf)\n",
    "            if nb_imp_index > 0:\n",
    "                print(\"Added \"+str(nb_imp_index)+ \" values, \"+str(nb_config-nb_imp_index)+\" left to choose \\n\")\n",
    "            # then we apply recursively this method to the rest of the dataframe\n",
    "            return select_exploitation(df.iloc[np.where(df[most_important_coef]==0)[0]], \n",
    "                                          sc[1:len(sc)],\n",
    "                                          config_selected)\n",
    "        \n",
    "        # otherwise we have enough values with this features activated\n",
    "        # to select all the remaining configurations\n",
    "        # so we apply the method to the dataframe containing all the feature activated\n",
    "        # and we select the configuration by using the followings features\n",
    "        else:\n",
    "            return select_exploitation(df.iloc[imp_index], \n",
    "                                 sc[1:len(sc)], \n",
    "                                 config_selected)\n",
    "\n",
    "exploitation_conf = select_exploitation(X_interact, sorted_coefs, [])\n",
    "\n",
    "print(\"Selected : \" + str(exploitation_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-] Exploration : Select specific configurations, similar between the source and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy gained : 0.000547608540106108\n",
      "Entropy gained : 0.0002969061712895637\n",
      "Entropy gained : 0.00014167539197548762\n",
      "Entropy gained : 0.0004862862461085379\n",
      "Entropy gained : 0.0002133764349618152\n",
      "Entropy gained : 3.961097664649787e-05\n",
      "\n",
      "Configurations kept for exploration : \n",
      "[ 522  970  261  260  880  352 1115 1029  208  842   87   52 1151  289\n",
      "   98  161 1021   26  319  686  828 1044  575  669  239  442  703  584\n",
      "  583  769  546  450  443  906  349  696  800  707  283 1102  211  240\n",
      "  602 1004  570  713  408   35  353 1127 1117  492  253  104  679  909\n",
      "   88  475  318  659]\n"
     ]
    }
   ],
   "source": [
    "ratio_exploration = 1-ratio_exploitation\n",
    "nb_exploration = int(config_tot*ratio_exploitation)\n",
    "\n",
    "# I choose to select the group in one step:\n",
    "# if you select config per config, you may choose a local optimal\n",
    "\n",
    "def select_exploration(df, exploitation_conf, id_target, number_group = 100):\n",
    "    \n",
    "    target = listVideo[id_target]\n",
    "    \n",
    "    # all the config left for exploration\n",
    "    # total minus those chosen for exploitation\n",
    "    explor_conf = np.setdiff1d(df.index, exploitation_conf)\n",
    "    \n",
    "    # initialization : we take the first nb_exploration config\n",
    "    best_explor = explor_conf[0:nb_exploration]\n",
    "    \n",
    "    # we group it with the exploitation configurations\n",
    "    conf = np.concatenate((exploitation_conf, best_explor), axis=0)\n",
    "    # for the moment, it's our best entropy\n",
    "    best_entropy  = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "    \n",
    "    # then we incrementally select the configurations to diminish the entropy \n",
    "    group_counter = 0\n",
    "    \n",
    "    while group_counter < number_group:\n",
    "        \n",
    "        group_counter +=1\n",
    "        \n",
    "        # current group to 'challenge' the best result\n",
    "        np.random.shuffle(explor_conf)\n",
    "        current_explor = explor_conf[0:nb_exploration]\n",
    "        \n",
    "        # we group it with the exploitation configurations\n",
    "        conf = np.concatenate((exploitation_conf, current_explor), axis=0)\n",
    "        \n",
    "        # we compute the Kullback Leibler divergence between the source and the target\n",
    "        current_entropy = sc.entropy(target.iloc[conf][predDimension], source.iloc[conf][predDimension])\n",
    "        \n",
    "        # we finally take the group giving the lowest entropy\n",
    "        # if this group is better than the best group, we replace it by the new one\n",
    "        if current_entropy > best_entropy:\n",
    "            print(\"Entropy gained : \"+str(current_entropy-best_entropy))\n",
    "            best_entropy = current_entropy\n",
    "            best_explor = current_explor\n",
    "    \n",
    "    return best_explor\n",
    "\n",
    "print(\"\\nConfigurations kept for exploration : \\n\" + \n",
    "      str(select_exploration(X_interact, exploitation_conf, 0, 1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Transfer the knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### I- Stepwise regression #################\n",
      "\n",
      "Add                              0 with p-value 5.1783e-205\n",
      "Add                             12 with p-value 1.1809e-35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/statsmodels/base/model.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/home/llesoil/anaconda3/envs/x264/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add                              7 with p-value 1.1977e-44\n",
      "Add                             82 with p-value 7.6015e-29\n",
      "Add                              6 with p-value 1.9188e-25\n",
      "Add                             13 with p-value 8.3363e-32\n",
      "Add                             14 with p-value 2.7087e-198\n",
      "Add                             84 with p-value 1.1647e-20\n",
      "Add                              3 with p-value 7.8187e-29\n",
      "Add                              1 with p-value 9.6967e-23\n",
      "Add                             83 with p-value 5.5034e-21\n",
      "Add                             75 with p-value 5.4457e-18\n",
      "Add                             70 with p-value 2.1972e-22\n",
      "Add                              9 with p-value 1.1661e-18\n",
      "Add                             72 with p-value 5.6538e-35\n",
      "Add                             42 with p-value 1.1999e-19\n",
      "Add                             11 with p-value 1.4369e-07\n",
      "Add                             10 with p-value 4.9131e-253\n",
      "Add                             73 with p-value 1.7055e-09\n",
      "Add                             74 with p-value 6.4725e-62\n",
      "Add                             50 with p-value 4.5682e-05\n",
      "Add                             93 with p-value 0.0012321\n",
      "Add                             16 with p-value 0.00096993\n",
      "Add                             27 with p-value 0.0011348\n",
      "Add                             76 with p-value 0.0064012\n",
      "Add                             77 with p-value 1.1025e-05\n",
      "Drop                             76 with p-value 0.85361\n",
      "Construction of the model completed!\n",
      "\n",
      "############### II- Sampling #################\n",
      "\n",
      "A- EXPLOITATION\n",
      "\n",
      "Feature : 74\n",
      "Added 59 values, 1 left to choose \n",
      "\n",
      "Feature : 73\n",
      "Feature : 72\n",
      "Feature : 6\n",
      "Feature : 84\n",
      "Feature : 83\n",
      "Feature : 82\n",
      "Feature : 7\n",
      "Feature : 12\n",
      "Feature : 13\n",
      "Feature : 14\n",
      "Feature : 11\n",
      "Feature : 10\n",
      "Feature : 9\n",
      "Feature : 3\n",
      "Feature : 70\n",
      "Feature : 75\n",
      "Feature : 1\n",
      "Feature : 42\n",
      "Feature : 50\n",
      "Feature : 93\n",
      "Feature : 27\n",
      "Feature : 77\n",
      "Feature : 16\n",
      "Feature : 0\n",
      "Selecting 1 configurations from the rest of the dataset!\n",
      "\n",
      "B- EXPLORATION\n",
      "\n",
      "Entropy gained : 5.9739721053967895e-05\n",
      "Entropy gained : 0.0006565844312546119\n",
      "Entropy gained : 0.0002796331979501663\n",
      "Entropy gained : 4.206784400634378e-06\n",
      "Entropy gained : 0.000307809549827915\n",
      "[ 679  433  339  281  416  373  123  340  458  919  261  423  903  200\n",
      "  330  661  599  358 1120   66  708  489 1140   95  474  257  324   34\n",
      " 1084  153  366  694 1128  756  904  742  570  198   88 1024  654  989\n",
      "  688  626  580  923  993  763 1069  933  663  295  316 1026  560  938\n",
      " 1081  363 1088  823  632   15 1076  811  616  523  484   16  841 1055\n",
      "  901   18  877  273  498  920  478  912  806  385  914 1047  150  630\n",
      "  540  105 1028  907  368  134  677   59  745  326  731 1113   79  743\n",
      "  266   85  572   89  612  443  231 1059  962  674 1003  577  601  703\n",
      "   76  769  891  532  981 1005  606  676]\n",
      "\n",
      "############### III- Transfer #################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14900471315052735"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def l2s_transfer(i, j, ratio_exploitation = 0.3, l2s_tr_ratio = 0.5, pct_test = 0.7):\n",
    "    \n",
    "    # to sample the source and the target using the same seed\n",
    "    random_state = np.random.randint(0,1000)\n",
    "\n",
    "    # a list of features to keep as explicative variables\n",
    "    keep_features = ['no_8x8dct','no_asm', 'no_cabac','no_deblock','no_fast_pskip', \n",
    "                     'no_mbtree','no_mixed_refs','no_weightb','rc_lookahead','ref']\n",
    "\n",
    "    # ordinal data to convert into dummies\n",
    "    to_dummy_features = ['rc_lookahead','ref']\n",
    "\n",
    "    # the source video\n",
    "    source = listVideo[i]\n",
    "    \n",
    "    # the number of config used in the training\n",
    "    config_tot = int(l2s_tr_ratio*(1-pct_test)*source.shape[1])\n",
    "\n",
    "    # transform some variables into dummies, to fit the orginal paper\n",
    "    # since we don't want to introduce a meaningless constant in the model, \n",
    "    # we have to keep all columns\n",
    "\n",
    "    dummies = pd.get_dummies(source[keep_features], \n",
    "                       drop_first = False,\n",
    "                       columns=to_dummy_features)\n",
    "\n",
    "    X_src = pd.DataFrame(np.array(dummies, dtype=int))\n",
    "\n",
    "\n",
    "    # add interactions\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only = True, include_bias = True)\n",
    "    X_interact = pd.DataFrame(np.array(poly.fit_transform(X_src),int))\n",
    "\n",
    "    # performance variable, to predict\n",
    "    y_src = np.array(source[predDimension], dtype=float)\n",
    "\n",
    "    # split train test (-> we only use X_src_train to sample l2s)\n",
    "    X_src_train, X_src_test, y_src_train, y_src_test = train_test_split(X_interact, \n",
    "                                                                        y_src, \n",
    "                                                                        test_size=pct_test, \n",
    "                                                                        random_state=random_state)\n",
    "\n",
    "    # we train the model with the training data\n",
    "    print(\"\\n############### I- Stepwise regression #################\\n\")\n",
    "    \n",
    "    selected_features = stepwise_selection(X_src_train, y_src_train)\n",
    "    \n",
    "    print(\"\\n############### II- Sampling #################\\n\")\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "\n",
    "    reg.fit(X_src_train[selected_features], y_src_train)\n",
    "\n",
    "    sorted_coefs = pd.Series(np.abs(reg.coef_), selected_features).sort_values(ascending=False).index\n",
    "\n",
    "    nb_config_exploitation = np.round(ratio_exploitation*config_tot)\n",
    "    \n",
    "    print(\"A- EXPLOITATION\\n\")\n",
    "    \n",
    "    exploitation_conf = select_exploitation(X_src_train, sorted_coefs, [])\n",
    "    \n",
    "    print(\"\\nB- EXPLORATION\\n\")\n",
    "    \n",
    "    exploration_conf = select_exploration(X_src_train, exploitation_conf, j, 1000)\n",
    "    \n",
    "    sampled_conf=np.concatenate((exploitation_conf,exploration_conf), axis=0)\n",
    "    \n",
    "    print(sampled_conf)\n",
    "    \n",
    "    print(\"\\n############### III- Transfer #################\\n\")\n",
    "    \n",
    "    # we split the source and the target\n",
    "    \n",
    "    target = listVideo[j]\n",
    "    \n",
    "    _, X_src_te, _, y_src_te = train_test_split(source[keep_features], \n",
    "                                                                    source[predDimension], \n",
    "                                                                    test_size=pct_test, \n",
    "                                                                    random_state=random_state)\n",
    "    \n",
    "        \n",
    "    _, X_tgt_te, _, y_tgt_te = train_test_split(target[keep_features], \n",
    "                                                                    target[predDimension],  \n",
    "                                                                    test_size=pct_test, \n",
    "                                                                    random_state=random_state)\n",
    "    X_src_tr = source[keep_features].iloc[sampled_conf]\n",
    "    y_src_tr = source[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    X_tgt_tr = target[keep_features].iloc[sampled_conf]\n",
    "    y_tgt_tr = target[predDimension].iloc[sampled_conf]\n",
    "    \n",
    "    lf = LinearRegression()\n",
    "    lf.fit(X_src_tr, y_src_tr)\n",
    "    y_src_pred_te = np.array(lf.predict(X_src_te)).reshape(-1,1)\n",
    "    \n",
    "    # The shift function, to transfer the prediction from the source to the target\n",
    "    shift = LinearRegression()\n",
    "    shift.fit(np.array(y_src_tr).reshape(-1,1), y_tgt_tr)\n",
    "    y_tgt_pred_te = shift.predict(y_src_pred_te)\n",
    "    \n",
    "    # We return the mean average percentage error \n",
    "    # between the real values of y_test from target \n",
    "    # and the predictions shifted \n",
    "    return min(mape(y_tgt_te, y_tgt_pred_te),1)\n",
    "    \n",
    "    \n",
    "l2s_transfer(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
